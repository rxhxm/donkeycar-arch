<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DonkeyCar Neural Network Visualization</title>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/controls/OrbitControls.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/three@0.132.2/examples/js/curves/QuadraticBezierCurve3.js"></script>
    <style>
        body {
            margin: 0;
            overflow: hidden;
            font-family: Arial, sans-serif;
            background-color: #f0f0f0;
        }
        #canvas-container {
            position: absolute;
            width: 100%;
            height: 100%;
        }
        #info-panel {
            position: absolute;
            top: 10px;
            left: 10px;
            background-color: rgba(255, 255, 255, 0.8);
            padding: 15px;
            border-radius: 5px;
            max-width: 300px;
            max-height: 80%;
            overflow-y: auto;
        }
        #model-selector {
            position: absolute;
            top: 10px;
            right: 10px;
            background-color: rgba(255, 255, 255, 0.8);
            padding: 15px;
            border-radius: 5px;
        }
        h2 {
            margin-top: 0;
            color: #333;
        }
        .layer-info {
            cursor: pointer;
            padding: 5px;
            margin: 2px 0;
            border-radius: 3px;
        }
        .layer-info:hover {
            background-color: #e0e0e0;
        }
        select {
            padding: 5px;
            border-radius: 3px;
        }
        #legend {
            margin-top: 20px;
            border-top: 1px solid #ccc;
            padding-top: 10px;
        }
        
        .legend-list {
            list-style-type: none;
            padding-left: 0;
        }
        
        .legend-list li {
            margin: 8px 0;
            display: flex;
            align-items: center;
        }
        
        .color-box {
            display: inline-block;
            width: 20px;
            height: 20px;
            margin-right: 10px;
            border-radius: 3px;
            border: 1px solid #333;
        }
    </style>
</head>
<body>
    <div id="canvas-container"></div>
    
    <div id="info-panel">
        <h2>DonkeyCar Neural Network</h2>
        <div id="layer-details">
            <p>Click on a layer to see details</p>
        </div>
        
        <div id="legend">
            <h3>Layer Types</h3>
            <ul class="legend-list">
                <li><span class="color-box" style="background-color:#4285F4"></span> Input / Flatten</li>
                <li><span class="color-box" style="background-color:#EA4335"></span> Convolution</li>
                <li><span class="color-box" style="background-color:#34A853"></span> Dropout / Output</li>
                <li><span class="color-box" style="background-color:#FBBC05"></span> Dense</li>
                <li><span class="color-box" style="background-color:#9C27B0"></span> LSTM / Behavior</li>
                <li><span class="color-box" style="background-color:#FF9800"></span> Concatenate</li>
            </ul>
        </div>
    </div>
    
    <div id="model-selector">
        <h3>Select Model Type</h3>
        <select id="model-type" onchange="changeModel()">
            <option value="linear">Linear</option>
            <option value="categorical">Categorical</option>
            <option value="behavioral">Behavioral</option>
            <option value="rgbd">RGBD</option>
            <option value="lstm">LSTM</option>
        </select>
    </div>

    <script>
        // Scene setup
        const scene = new THREE.Scene();
        scene.background = new THREE.Color(0xf0f0f0);
        
        // Camera setup
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.z = 15;
        camera.position.y = 5;
        
        // Renderer setup
        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.getElementById('canvas-container').appendChild(renderer.domElement);
        
        // Controls
        const controls = new THREE.OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;
        controls.dampingFactor = 0.25;
        
        // Lighting
        const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
        scene.add(ambientLight);
        
        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.8);
        directionalLight.position.set(1, 1, 1);
        scene.add(directionalLight);
        
        // Model definitions
        const modelDefinitions = {
            linear: {
                name: "KerasLinear",
                description: "Direct regression approach with one neuron per output for continuous predictions using mean squared error (MSE) for steering and throttle.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Flatten" },
                    { type: "Dense", units: 100, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Dense", units: 50, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Output", units: 1, name: "steering" },
                    { type: "Output", units: 1, name: "throttle" }
                ]
            },
            
            categorical: {
                name: "KerasCategorical",
                description: "Discretizes steering and throttle into fixed bins (15 bins for steering, 20 for throttle) using binning methods, with categorical cross-entropy loss. Output probabilities are 'unbinned' back into continuous values.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Flatten" },
                    { type: "Dense", units: 100, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Dense", units: 50, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Output", units: 15, name: "angle_out", activation: "softmax" },
                    { type: "Output", units: 20, name: "throttle_out", activation: "softmax" }
                ]
            },
            
            memory: {
                name: "KerasMemory",
                description: "Extends the linear model by incorporating a memory of previous steering/throttle commands for smoother outputs. Uses a deque to update memory with each inference call.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Flatten" },
                    { type: "Input", shape: [6], name: "mem_in" },
                    { type: "Dense", units: 24, activation: "relu", name: "mem_dense" },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Dense", units: 12, activation: "relu", name: "mem_dense2" },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Concatenate", name: "concat" },
                    { type: "Dense", units: 100, activation: "relu" },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Dense", units: 50, activation: "relu" },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Output", units: 1, name: "steering", activation: "tanh" },
                    { type: "Output", units: 1, name: "throttle", activation: "sigmoid" }
                ]
            },
            
            inferred: {
                name: "KerasInferred",
                description: "Simplifies the task by only having the network directly predict steering. The throttle is then derived from the steering value using an external utility function.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Flatten" },
                    { type: "Dense", units: 100, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Dense", units: 50, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Output", units: 1, name: "steering" }
                ]
            },
            
            imu: {
                name: "KerasIMU",
                description: "Combines image data with an IMU vector (accelerometer/gyroscope readings) via two separate branches that merge later. Uses MSE on continuous steering and throttle outputs.",
                layers: [
                    // Image branch
                    { type: "Input", shape: [120, 160, 3], name: "img_in", branch: "main" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Flatten", branch: "main" },
                    { type: "Dense", units: 100, activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.1, branch: "main" },
                    
                    // IMU branch
                    { type: "Input", shape: [6], name: "imu_in", branch: "imu" },
                    { type: "Dense", units: 14, activation: "relu", branch: "imu" },
                    { type: "Dense", units: 14, activation: "relu", branch: "imu" },
                    { type: "Dense", units: 14, activation: "relu", branch: "imu" },
                    
                    // Merged
                    { type: "Concatenate", branches: ["main", "imu"], branch: "merged" },
                    { type: "Dense", units: 50, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.1, branch: "merged" },
                    { type: "Dense", units: 50, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.1, branch: "merged" },
                    
                    // Output
                    { type: "Output", units: 1, name: "steering", branch: "output" },
                    { type: "Output", units: 1, name: "throttle", branch: "output" }
                ]
            },
            
            behavioral: {
                name: "KerasBehavioral",
                description: "Incorporates a behavioral vector (e.g., one-hot driving mode) alongside the image to guide outputs. Similar binning to categorical model, using categorical cross-entropy loss.",
                layers: [
                    // Image branch
                    { type: "Input", shape: [120, 160, 3], name: "img_in", branch: "main" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.2, branch: "main" },
                    { type: "Flatten", branch: "main" },
                    { type: "Dense", units: 100, activation: "relu", branch: "main" },
                    { type: "Dropout", rate: 0.1, branch: "main" },
                    
                    // Behavior branch
                    { type: "Input", shape: [2], name: "behavior_in", branch: "behavior" },
                    { type: "Dense", units: 4, activation: "relu", branch: "behavior" },
                    { type: "Dense", units: 4, activation: "relu", branch: "behavior" },
                    { type: "Dense", units: 4, activation: "relu", branch: "behavior" },
                    
                    // Merged
                    { type: "Concatenate", branches: ["main", "behavior"], branch: "merged" },
                    { type: "Dense", units: 100, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.1, branch: "merged" },
                    { type: "Dense", units: 50, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.1, branch: "merged" },
                    
                    // Output
                    { type: "Output", units: 15, name: "angle_out", activation: "softmax", branch: "output" },
                    { type: "Output", units: 20, name: "throttle_out", activation: "softmax", branch: "output" }
                ]
            },
            
            localizer: {
                name: "KerasLocalizer",
                description: "Predicts steering, throttle, and adds a localization output (track segment classification). Uses MSE for steering/throttle plus a softmax classification for location.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Flatten" },
                    { type: "Dense", units: 100, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Dense", units: 50, activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Output", units: 1, name: "angle" },
                    { type: "Output", units: 1, name: "throttle" },
                    { type: "Output", units: 8, name: "location", activation: "softmax" }
                ]
            },
            
            lstm: {
                name: "KerasLSTM",
                description: "Uses an LSTM network to process a sequence of images, capturing temporal dynamics for smoother control. Maintains a deque to build the image sequence.",
                layers: [
                    { type: "Input", shape: [3, 120, 160, 3], name: "img_in" },
                    { type: "TimeDistributed", layer: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "TimeDistributed", layer: "Dropout", rate: 0.3 },
                    { type: "TimeDistributed", layer: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "TimeDistributed", layer: "Dropout", rate: 0.3 },
                    { type: "TimeDistributed", layer: "Conv2D", filters: 32, kernel: [3, 3], strides: [2, 2], activation: "relu" },
                    { type: "TimeDistributed", layer: "Dropout", rate: 0.3 },
                    { type: "TimeDistributed", layer: "Conv2D", filters: 32, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "TimeDistributed", layer: "Dropout", rate: 0.3 },
                    { type: "TimeDistributed", layer: "MaxPooling2D", pool_size: [2, 2] },
                    { type: "TimeDistributed", layer: "Flatten" },
                    { type: "TimeDistributed", layer: "Dense", units: 100, activation: "relu" },
                    { type: "TimeDistributed", layer: "Dropout", rate: 0.3 },
                    { type: "LSTM", units: 128, return_sequences: true },
                    { type: "Dropout", rate: 0.1 },
                    { type: "LSTM", units: 128, return_sequences: false },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Dense", units: 128, activation: "relu" },
                    { type: "Dropout", rate: 0.1 },
                    { type: "Dense", units: 64, activation: "relu" },
                    { type: "Dense", units: 10, activation: "relu" },
                    { type: "Output", units: 2, name: "model_outputs" }
                ]
            },
            
            cnn_3d: {
                name: "Keras3D_CNN",
                description: "Processes a sequence of images as a 3D volume using 3D convolutions to capture spatiotemporal features. Employs 3D convolutions and pooling with MSE loss.",
                layers: [
                    { type: "Input", shape: [20, 120, 160, 3], name: "img_in" },
                    { type: "Conv3D", filters: 16, kernel: [3, 3, 3], strides: [1, 3, 3], padding: "same", activation: "relu" },
                    { type: "MaxPooling3D", pool_size: [1, 2, 2], strides: [1, 2, 2] },
                    { type: "Conv3D", filters: 32, kernel: [3, 3, 3], strides: [1, 1, 1], padding: "same", activation: "relu" },
                    { type: "MaxPooling3D", pool_size: [1, 2, 2], strides: [1, 2, 2] },
                    { type: "Conv3D", filters: 64, kernel: [3, 3, 3], strides: [1, 1, 1], padding: "same", activation: "relu" },
                    { type: "MaxPooling3D", pool_size: [1, 2, 2], strides: [1, 2, 2] },
                    { type: "Conv3D", filters: 128, kernel: [3, 3, 3], strides: [1, 1, 1], padding: "same", activation: "relu" },
                    { type: "MaxPooling3D", pool_size: [1, 2, 2], strides: [1, 2, 2] },
                    { type: "Flatten" },
                    { type: "Dense", units: 256 },
                    { type: "BatchNormalization" },
                    { type: "Activation", activation: "relu" },
                    { type: "Dropout", rate: 0.5 },
                    { type: "Dense", units: 256 },
                    { type: "BatchNormalization" },
                    { type: "Activation", activation: "relu" },
                    { type: "Dropout", rate: 0.5 },
                    { type: "Output", units: 2, name: "outputs" }
                ]
            },
            
            latent: {
                name: "KerasLatent",
                description: "Implements an autoencoder-like structure that encodes an image to a latent space and decodes it, alongside predicting controls. Includes both image reconstruction and control outputs.",
                layers: [
                    { type: "Input", shape: [120, 160, 3], name: "img_in" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 32, kernel: [3, 3], strides: [1, 1], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [2, 2], activation: "relu" },
                    { type: "Dropout", rate: 0.2 },
                    { type: "Conv2D", filters: 64, kernel: [1, 1], strides: [2, 2], activation: "relu", name: "latent" },
                    
                    // Decoder branch
                    { type: "Conv2DTranspose", filters: 64, kernel: [3, 3], strides: [2, 2], branch: "decoder" },
                    { type: "Conv2DTranspose", filters: 64, kernel: [3, 3], strides: [2, 2], branch: "decoder" },
                    { type: "Conv2DTranspose", filters: 32, kernel: [3, 3], strides: [2, 2], branch: "decoder" },
                    { type: "Conv2DTranspose", filters: 32, kernel: [3, 3], strides: [2, 2], branch: "decoder" },
                    { type: "Conv2DTranspose", filters: 32, kernel: [3, 3], strides: [2, 2], branch: "decoder" },
                    { type: "Conv2DTranspose", filters: 1, kernel: [3, 3], strides: [2, 2], name: "img_out", branch: "decoder" },
                    
                    // Control branch
                    { type: "Flatten", branch: "control" },
                    { type: "Dense", units: 256, activation: "relu", branch: "control" },
                    { type: "Dropout", rate: 0.2, branch: "control" },
                    { type: "Dense", units: 100, activation: "relu", branch: "control" },
                    { type: "Dropout", rate: 0.2, branch: "control" },
                    { type: "Dense", units: 50, activation: "relu", branch: "control" },
                    { type: "Dropout", rate: 0.2, branch: "control" },
                    { type: "Output", units: 1, name: "steering", branch: "control" },
                    { type: "Output", units: 1, name: "throttle", branch: "control" }
                ]
            },
            
            rgbd: {
                name: "KerasRGBD",
                description: "Enhances the linear model by incorporating a depth map with the RGB image via two parallel branches that are later merged. Processes image and depth data separately before combining.",
                layers: [
                    // Image branch
                    { type: "Input", shape: [120, 160, 3], name: "img_in", branch: "image" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    { type: "Flatten", branch: "image" },
                    { type: "Dense", units: 100, activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    { type: "Dense", units: 50, activation: "relu", branch: "image" },
                    { type: "Dropout", rate: 0.2, branch: "image" },
                    
                    // Depth branch
                    { type: "Input", shape: [120, 160], name: "depth_in", branch: "depth" },
                    { type: "Conv2D", filters: 24, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    { type: "Conv2D", filters: 32, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    { type: "Conv2D", filters: 64, kernel: [5, 5], strides: [2, 2], activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    { type: "Conv2D", filters: 64, kernel: [3, 3], strides: [1, 1], activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    { type: "Flatten", branch: "depth" },
                    { type: "Dense", units: 100, activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    { type: "Dense", units: 50, activation: "relu", branch: "depth" },
                    { type: "Dropout", rate: 0.2, branch: "depth" },
                    
                    // Merged
                    { type: "Concatenate", branches: ["image", "depth"], branch: "merged" },
                    { type: "Dense", units: 50, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.2, branch: "merged" },
                    { type: "Dense", units: 50, activation: "relu", branch: "merged" },
                    { type: "Dropout", rate: 0.2, branch: "merged" },
                    
                    // Output
                    { type: "Output", units: 1, name: "steering", branch: "output" },
                    { type: "Output", units: 1, name: "throttle", branch: "output" }
                ]
            }
        };

        // Update the createBranchedModelVisualization function to handle non-linear layouts
        function createBranchedModelVisualization(modelDef) {
            const scene = new THREE.Scene();
            layerObjects = [];
            
            // Use branch information to position layers
            const branches = {};
            let branchLayers = {};
            
            // First pass - identify branches
            modelDef.layers.forEach(layer => {
                const branchName = layer.branch || 'main';
                if (!branches[branchName]) {
                    branches[branchName] = {
                        xOffset: 0,
                        zOffset: 0,
                        yStart: 10,
                        spacing: -1.5
                    };
                    
                    // Set offsets for different branches
                    if (branchName === 'behavior' || branchName === 'depth') {
                        branches[branchName].xOffset = 3;
                    } else if (branchName === 'imu') {
                        branches[branchName].xOffset = 3.5;
                    } else if (branchName === 'rgb' || branchName === 'image') {
                        branches[branchName].xOffset = -3;
                    } else if (branchName === 'decoder') {
                        branches[branchName].xOffset = 2;
                        branches[branchName].zOffset = 2;
                    } else if (branchName === 'control') {
                        branches[branchName].xOffset = -2;
                        branches[branchName].zOffset = 2;
                    } else if (branchName === 'merged') {
                        branches[branchName].xOffset = 0;
                        branches[branchName].zOffset = 0;
                    }
                }
                
                if (!branchLayers[branchName]) {
                    branchLayers[branchName] = [];
                }
            });
            
            // Second pass - create layers with branch-specific positioning
            let currentPos = {};
            Object.keys(branches).forEach(branch => {
                currentPos[branch] = {
                    y: branches[branch].yStart,
                    x: branches[branch].xOffset,
                    z: branches[branch].zOffset,
                };
            });
            
            // Add sinusoidal variation to make branches meander
            let angleOffset = 0;
            
            // Create layers with proper positioning
            modelDef.layers.forEach(layer => {
                const branchName = layer.branch || 'main';
                const pos = currentPos[branchName];
                
                // Add meandering to the branch
                const isMeander = modelDef.name === "KerasBehavioral" || modelDef.name === "KerasRGBD";
                
                if (isMeander && layer.type !== "Input") {
                    // Add sinusoidal variation
                    angleOffset += 0.2;
                    const amplitude = 0.5;
                    pos.x += Math.sin(angleOffset) * amplitude;
                    pos.z += Math.cos(angleOffset) * amplitude * 0.3;
                }
                
                // Create the mesh for this layer
                const mesh = createLayerMesh(layer, pos.x, pos.y, pos.z);
                scene.add(mesh);
                layerObjects.push(mesh);
                branchLayers[branchName].push(mesh);
                
                // Move down for next layer in this branch
                pos.y += branches[branchName].spacing;
            });
            
            // Create connections between layers within branches
            Object.keys(branchLayers).forEach(branchName => {
                const layers = branchLayers[branchName];
                for (let i = 0; i < layers.length - 1; i++) {
                    createConnection(layers[i], layers[i+1]);
                }
            });
            
            // Create connections between branches for merge points
            modelDef.layers.forEach(layer => {
                if (layer.type === "Concatenate" && layer.branches) {
                    const targetMesh = getLayerMeshByName(layer.type, layer.branch);
                    
                    // Connect each source branch to the concatenate layer
                    layer.branches.forEach(sourceBranch => {
                        // Find the last layer of the source branch
                        const sourceLayers = branchLayers[sourceBranch];
                        if (sourceLayers && sourceLayers.length > 0) {
                            const sourceMesh = sourceLayers[sourceLayers.length - 1];
                            createConnection(sourceMesh, targetMesh);
                        }
                    });
                }
            });
            
            // Helper function to get a mesh by layer name and branch
            function getLayerMeshByName(type, branch) {
                for (const obj of layerObjects) {
                    if (obj.userData && obj.userData.layer && 
                        obj.userData.layer.type === type && 
                        obj.userData.layer.branch === branch) {
                        return obj;
                    }
                }
                return null;
            }
            
            // Create a camera and add it to the scene
            const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 15;
            camera.position.y = 0;
            
            // Create a renderer
            const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth * 0.7, window.innerHeight * 0.8);
            document.getElementById('model-container').appendChild(renderer.domElement);
            
            // Add lights
            const ambientLight = new THREE.AmbientLight(0xffffff, 0.5);
            scene.add(ambientLight);
            
            const pointLight = new THREE.PointLight(0xffffff, 1);
            pointLight.position.set(10, 10, 10);
            scene.add(pointLight);
            
            // Add OrbitControls
            const controls = new THREE.OrbitControls(camera, renderer.domElement);
            controls.enableDamping = true;
            controls.dampingFactor = 0.05;
            
            // Animation function
            function animate() {
                requestAnimationFrame(animate);
                controls.update();
                renderer.render(scene, camera);
            }
            
            animate();
            
            // Return the scene for potential further manipulation
            return scene;
        }

        // Update the function that creates layer details to include comprehensive descriptions
        function updateLayerDetails(layer) {
            let details = `<h3>${layer.type}${layer.name ? ': ' + layer.name : ''}</h3>`;
            
            if (layer.type === "Input") {
                details += `<p>Shape: ${JSON.stringify(layer.shape)}</p>`;
                details += `<p>The input layer that receives the raw data (image, sensor values, etc.)</p>`;
            } else if (layer.type === "Conv2D") {
                details += `<p>Filters: ${layer.filters}, Kernel: ${JSON.stringify(layer.kernel)}, Strides: ${JSON.stringify(layer.strides)}</p>`;
                details += `<p>Convolutional layer that extracts spatial features from the input using learnable filters</p>`;
            } else if (layer.type === "Dense") {
                details += `<p>Units: ${layer.units}, Activation: ${layer.activation || 'linear'}</p>`;
                details += `<p>Fully connected layer where each neuron connects to all neurons in the previous layer</p>`;
            } else if (layer.type === "Dropout") {
                details += `<p>Rate: ${layer.rate}</p>`;
                details += `<p>Regularization layer that randomly sets input units to 0 during training to prevent overfitting</p>`;
            } else if (layer.type === "Output") {
                details += `<p>Units: ${layer.units}, Name: ${layer.name}</p>`;
                details += `<p>Final layer that produces the model's predictions (steering angle, throttle, etc.)</p>`;
            } else if (layer.type === "LSTM") {
                details += `<p>Units: ${layer.units}, Return Sequences: ${layer.return_sequences}</p>`;
                details += `<p>Long Short-Term Memory layer that captures temporal dependencies in sequential data</p>`;
            } else if (layer.type === "TimeDistributed") {
                details += `<p>Wrapped Layer: ${layer.layer}</p>`;
                details += `<p>Applies the same operation to every temporal slice of the input</p>`;
            } else if (layer.type === "Concatenate") {
                details += `<p>Merges features from multiple branches: ${layer.branches ? layer.branches.join(', ') : ''}</p>`;
                details += `<p>Combines features from different pathways in the network architecture</p>`;
            } else if (layer.type === "Conv3D") {
                details += `<p>Filters: ${layer.filters}, Kernel: ${JSON.stringify(layer.kernel)}, Strides: ${JSON.stringify(layer.strides)}</p>`;
                details += `<p>3D convolutional layer for processing spatiotemporal data (like image sequences)</p>`;
            } else if (layer.type === "Conv2DTranspose") {
                details += `<p>Filters: ${layer.filters}, Kernel: ${JSON.stringify(layer.kernel)}, Strides: ${JSON.stringify(layer.strides)}</p>`;
                details += `<p>Transposed convolution layer used in decoder networks for upsampling feature maps</p>`;
            } else if (layer.type === "Flatten") {
                details += `<p>Transforms multi-dimensional input to a flat 1D vector</p>`;
            } else if (layer.type === "MaxPooling2D" || layer.type === "MaxPooling3D") {
                details += `<p>Pool Size: ${JSON.stringify(layer.pool_size)}, Strides: ${JSON.stringify(layer.strides)}</p>`;
                details += `<p>Downsampling layer that reduces dimensions and maintains the most important features</p>`;
            } else if (layer.type === "BatchNormalization") {
                details += `<p>Normalizes layer inputs to stabilize and accelerate training</p>`;
            } else if (layer.type === "Activation") {
                details += `<p>Activation: ${layer.activation}</p>`;
                details += `<p>Applies a non-linear activation function to the input</p>`;
            }

                };
                
                // Layer colors
                const layerColors = {
                    "Input": 0x4285F4,
                    "Conv2D": 0xEA4335,
                    "Conv2D Branch 1": 0xEA4335,
                    "Conv2D Branch 2": 0xFBBC05,
                    "Dropout": 0x34A853,
                    "Flatten": 0x4285F4,
                    "Dense": 0xFBBC05,
                    "Output": 0x34A853,
                    "TimeDistributed Conv2D": 0xEA4335,
                    "TimeDistributed Dropout": 0x34A853,
                    "TimeDistributed Flatten": 0x4285F4,
                    "LSTM": 0x9C27B0,
                    "BehaviorProcessing": 0x9C27B0,
                    "Concatenate": 0xFF9800
                };
                
                // Layer shapes
                const layerShapes = {
                    "Input": "box",
                    "Conv2D": "box",
                    "Conv2D Branch 1": "box",
                    "Conv2D Branch 2": "box",
                    "Dropout": "sphere",
                    "Flatten": "box",
                    "Dense": "cylinder",
                    "Output": "sphere",
                    "TimeDistributed Conv2D": "box",
                    "TimeDistributed Dropout": "sphere",
                    "TimeDistributed Flatten": "box",
                    "LSTM": "cylinder",
                    "BehaviorProcessing": "cylinder",
                    "Concatenate": "sphere"
                };
                
                // Layer objects for raycasting
                const layerObjects = [];
                
                // Current model
                let currentModel = "linear";
                
                // Create model visualization
                function createModelVisualization(modelType) {
                    // Clear existing visualization
                    layerObjects.forEach(obj => scene.remove(obj));
                    layerObjects.length = 0;
                    
                    const model = modelDefinitions[modelType];
                    const layers = model.layers;
                    
                    // Update info panel
                    document.getElementById('layer-details').innerHTML = `
                        <h3>${model.name}</h3>
                        <p>${model.description}</p>
                        <p>Click on a layer to see details</p>
                    `;
                    
                    // Calculate total height needed
                    const totalHeight = layers.length * 1.5;
                    const startY = totalHeight / 2;
                    
                    // Create layers
                    layers.forEach((layer, index) => {
                        const y = startY - index * 1.5;
                        
                        let geometry;
                        const layerType = layer.type;
                        
                        // Determine geometry based on layer type
                        switch (layerShapes[layerType] || "box") {
                            case "box":
                                // Size based on layer type
                                let width = 4;
                                let height = 0.5;
                                let depth = 2;
                                
                                if (layerType.includes("Input")) {
                                    width = 5;
                                    depth = 3;
                                } else if (layerType.includes("Conv")) {
                                    width = 4;
                                    depth = 2.5;
                                } else if (layerType === "Flatten") {
                                    width = 3;
                                    depth = 1;
                                }
                                
                                geometry = new THREE.BoxGeometry(width, height, depth);
                                break;
                            case "cylinder":
                                const radius = layerType.includes("Dense") ? 
                                    (layer.units > 50 ? 2 : 1.5) : 1.5;
                                geometry = new THREE.CylinderGeometry(radius, radius, 0.5, 32);
                                break;
                            case "sphere":
                                const sphereRadius = layerType === "Output" ? 0.6 : 0.4;
                                geometry = new THREE.SphereGeometry(sphereRadius, 32, 32);
                                break;
                            default:
                                geometry = new THREE.BoxGeometry(3, 0.5, 2);
                        }
                        
                        // Create material
                        const material = new THREE.MeshPhongMaterial({
                            color: layerColors[layerType] || 0x999999,
                            transparent: true,
                            opacity: 0.8,
                            specular: 0x111111,
                            shininess: 30
                        });
                        
                        // Create mesh
                        const mesh = new THREE.Mesh(geometry, material);
                        mesh.position.set(0, y, 0);
                        
                        // Special positioning for branch layers in RGBD
                        if (modelType === "rgbd") {
                            if (layerType === "Conv2D Branch 1" || 
                                (index > 2 && index < 12)) {
                                mesh.position.x = -2;
                            } else if (layerType === "Conv2D Branch 2" || 
                                    (index > 11 && index < 19)) {
                                mesh.position.x = 2;
                            }
                        }
                        
                        // Special positioning for behavioral model
                        if (modelType === "behavioral") {
                            if (layerType === "BehaviorProcessing") {
                                mesh.position.x = 2;
                            } else if (index > 0 && index < 13) {
                                mesh.position.x = -2;
                            }
                        }
                        
                        // Store layer info in the mesh for raycasting
                        mesh.userData = {
                            layer: layer,
                            index: index
                        };
                        
                        scene.add(mesh);
                        layerObjects.push(mesh);
                        
                        // Add connections between layers
                        if (index > 0) {
                            // Skip connections for certain layer combinations
                            let skipConnection = false;
                            
                            if (modelType === "rgbd") {
                                if ((index === 12 && layers[index-1].type !== "Conv2D Branch 2") ||
                                    (index === 2 && layers[index-1].type === "Input")) {
                                    skipConnection = true;
                                }
                            }
                            
                            if (modelType === "behavioral") {
                                if ((index === 13 && layers[index-1].type !== "BehaviorProcessing") ||
                                    (index === 2 && layers[index-1].type === "Input")) {
                                    skipConnection = true;
                                }
                            }
                            
                            if (!skipConnection) {
                                const prevMesh = layerObjects[layerObjects.length - 2];
                                
                                // Create connection line
                                const points = [];
                                points.push(new THREE.Vector3(prevMesh.position.x, prevMesh.position.y, prevMesh.position.z));
                                points.push(new THREE.Vector3(mesh.position.x, mesh.position.y, mesh.position.z));
                                
                                const lineGeometry = new THREE.BufferGeometry().setFromPoints(points);
                                const lineMaterial = new THREE.LineBasicMaterial({ color: 0x999999 });
                                const line = new THREE.Line(lineGeometry, lineMaterial);
                                
                                scene.add(line);
                                layerObjects.push(line);
                            }
                        }
                    });
            }
            
            // Change model
            function changeModel() {
                const modelType = document.getElementById('model-type').value;
                currentModel = modelType;
                createModelVisualization(modelType);
            }
            
            // Initial model creation
            createModelVisualization(currentModel);
            
            // Raycaster for interaction
            const raycaster = new THREE.Raycaster();
            const mouse = new THREE.Vector2();
            
            function onMouseClick(event) {
                // Calculate mouse position in normalized device coordinates
                mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
                mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
                
                // Update the raycaster
                raycaster.setFromCamera(mouse, camera);
                
                // Calculate objects intersecting the ray
                const intersects = raycaster.intersectObjects(layerObjects.filter(obj => obj.type === "Mesh"));
                
                if (intersects.length > 0) {
                    const object = intersects[0].object;
                    
                    // Only process mesh objects with layer data
                    if (object.userData && object.userData.layer) {
                        const layer = object.userData.layer;
                        
                        // Highlight selected layer
                        layerObjects.forEach(obj => {
                            if (obj.type === "Mesh" && obj.material && obj.material.color) {
                                if (obj === object) {
                                    obj.material.emissive.set(0x333333);
                                } else {
                                    obj.material.emissive.set(0x000000);
                                }
                            }
                        });
                        
                        // Update info panel with layer details
                        let details = `<h3>${layer.type} Layer</h3>`;
                        
                        // Add layer-specific details
                        if (layer.type.includes("Input")) {
                            details += `<p>Shape: ${JSON.stringify(layer.shape)}</p>`;
                            details += `<p>Name: ${layer.name}</p>`;
                        } else if (layer.type.includes("Conv")) {
                            details += `<p>Filters: ${layer.filters}</p>`;
                            details += `<p>Kernel: ${JSON.stringify(layer.kernel)}</p>`;
                            details += `<p>Strides: ${JSON.stringify(layer.strides)}</p>`;
                            details += `<p>Activation: ${layer.activation}</p>`;
                        } else if (layer.type.includes("Dropout")) {
                            details += `<p>Rate: ${layer.rate}</p>`;
                        } else if (layer.type.includes("Dense")) {
                            details += `<p>Units: ${layer.units}</p>`;
                            details += `<p>Activation: ${layer.activation}</p>`;
                        } else if (layer.type.includes("Output")) {
                            details += `<p>Units: ${layer.units}</p>`;
                            if (layer.activation) {
                                details += `<p>Activation: ${layer.activation}</p>`;
                            }
                            details += `<p>Name: ${layer.name}</p>`;
                        } else if (layer.type === "LSTM") {
                            details += `<p>Units: ${layer.units}</p>`;
                            details += `<p>Return Sequences: ${layer.return_sequences}</p>`;
                        } else if (layer.type === "BehaviorProcessing") {
                            details += `<p>Units: ${layer.units}</p>`;
                        } else if (layer.type === "Concatenate") {
                            details += `<p>Combines features from multiple branches</p>`;
                        } else if (layer.type === "Flatten") {
                            details += `<p>Transforms multi-dimensional input to 1D vector</p>`;
                        }
                        
                        document.getElementById('layer-details').innerHTML = details;
                        
                        // Log for debugging
                        console.log("Layer clicked:", layer);
                    }
                }
            }
            
            // Handle window resize
            function onWindowResize() {
                camera.aspect = window.innerWidth / window.innerHeight;
                camera.updateProjectionMatrix();
                renderer.setSize(window.innerWidth, window.innerHeight);
            }
            
            // Animation loop
            function animate() {
                requestAnimationFrame(animate);
                controls.update();
                renderer.render(scene, camera);
            }
            
            // Event listeners
            window.addEventListener('resize', onWindowResize, false);
            window.addEventListener('click', onMouseClick, false);
            
            // Start animation
            animate();

            // Add a debug function to test click handling
            window.checkLayerObjects = function() {
                console.log("Layer objects:", layerObjects);
                return layerObjects.filter(obj => obj.type === "Mesh" && obj.userData && obj.userData.layer).length + " clickable objects";
            };

            // Update the branch positioning logic in createBranchedModelVisualization function
            function createBranchedModelVisualization(modelDef) {
                // Identify all unique branches
                const branches = {};
                const branchPositions = {};
                
                // First pass - identify branches and count layers in each
                modelDef.layers.forEach(layer => {
                    const branchName = layer.branch || 'main';
                    if (!branches[branchName]) {
                        branches[branchName] = [];
                    }
                    branches[branchName].push(layer);
                });
                
                // Track branch meshes
                const branchLayers = {};
                
                // Apply a meandering pattern to layer positions
                // For behavioral and RGBD models
                let xOffset = 0;
                let zOffset = 0;
                const isRGBD = modelDef.name.includes("RGBD");
                const isBehavioral = modelDef.name.includes("Behavioral");
                
                // Process each branch
                Object.keys(branches).forEach(branchName => {
                    const branchLayers = branches[branchName];
                    
                    // Set starting position with some randomness for non-linear layout
                    let xPos = 0;
                    let yPos = 10; // Start at the top
                    
                    // Add some offset for side branches
                    if (branchName === 'behavior' || branchName === 'depth') {
                        xPos = 3;  // Position side branches to the right
                    } else if (branchName === 'rgb') {
                        xPos = -3; // Position RGB branch to the left for RGBD model
                    } else if (branchName === 'steering') {
                        xPos = -1.5;
                        yPos = -8; // Lower position for output
                    } else if (branchName === 'throttle') {
                        xPos = 1.5;
                        yPos = -8; // Lower position for output
                    }
                    
                    // Save the branch position
                    branchPositions[branchName] = { 
                        x: xPos,
                        startY: yPos,
                        spacing: -1.5 // Vertical spacing between layers
                    };
                    
                    if (!branchLayers[branchName]) {
                        branchLayers[branchName] = [];
                    }
                });
                
                // Create meshes for each layer with meandering positions
                modelDef.layers.forEach((layer, index) => {
                    const branchName = layer.branch || 'main';
                    const position = branchPositions[branchName];
                    const branchIndex = branches[branchName].indexOf(layer);
                    
                    // Calculate position with meandering
                    let xPos = position.x;
                    let yPos = position.startY + (branchIndex * position.spacing);
                    let zPos = 0;
                    
                    // Add meandering effect based on layer index
                    if (isBehavioral || isRGBD) {
                        // Main branch should have a slight curve
                        if (branchName === 'main' || branchName === 'merged') {
                            // Create a slight S-curve pattern
                            xPos += Math.sin(branchIndex * 0.4) * 0.7;
                            zPos += Math.cos(branchIndex * 0.3) * 0.2;
                        } 
                        // Behavior and depth branches should curve toward the merge point
                        else if (branchName === 'behavior' || branchName === 'depth') {
                            const progress = branchIndex / (branches[branchName].length - 1 || 1);
                            xPos = position.x * (1 - progress) + (progress * 0.5); // Move toward center
                        }
                        // RGB branch should curve toward the merge point
                        else if (branchName === 'rgb') {
                            const progress = branchIndex / (branches[branchName].length - 1 || 1);
                            xPos = position.x * (1 - progress) + (progress * -0.5); // Move toward center
                        }
                    }
                    
                    // Create mesh for this layer
                    const mesh = createLayerMesh(layer, xPos, yPos, zPos);
                    scene.add(mesh);
                    layerObjects.push(mesh);
                    
                    // Track the mesh for this branch
                    if (!branchLayers[branchName]) {
                        branchLayers[branchName] = [];
                    }
                    branchLayers[branchName].push(mesh);
                });
                
                // Create connections with curved paths
                Object.keys(branches).forEach(branchName => {
                    const layers = branchLayers[branchName];
                    
                    // Connect layers within the branch
                    for (let i = 1; i < layers.length; i++) {
                        const fromMesh = layers[i-1];
                        const toMesh = layers[i];
                        
                        createCurvedConnection(fromMesh, toMesh);
                    }
                });
                
                // Create connections between branches for concatenate layers
                modelDef.layers.forEach(layer => {
                    if (layer.type === 'Concatenate' && layer.branches) {
                        const concatMesh = findMeshForLayer(layer);
                        
                        // Connect from the last layer of each input branch to this concatenate layer
                        layer.branches.forEach(inputBranchName => {
                            if (branchLayers[inputBranchName] && branchLayers[inputBranchName].length > 0) {
                                const lastMesh = branchLayers[inputBranchName][branchLayers[inputBranchName].length - 1];
                                createCurvedConnection(lastMesh, concatMesh);
                            }
                        });
                    }
                });
                
                // Connect merged output to final outputs
                if (branchLayers['merged'] && branchLayers['merged'].length > 0) {
                    const lastMergedMesh = branchLayers['merged'][branchLayers['merged'].length - 1];
                    
                    // Connect to steering and throttle outputs
                    ['steering', 'throttle'].forEach(outputBranch => {
                        if (branchLayers[outputBranch] && branchLayers[outputBranch].length > 0) {
                            createCurvedConnection(lastMergedMesh, branchLayers[outputBranch][0]);
                        }
                    });
                }
                
                // Create curved connection between two meshes
                function createCurvedConnection(fromMesh, toMesh) {
                    // Create a curved path with control points
                    const curve = new THREE.QuadraticBezierCurve3(
                        new THREE.Vector3(fromMesh.position.x, fromMesh.position.y, fromMesh.position.z),
                        new THREE.Vector3(
                            (fromMesh.position.x + toMesh.position.x) / 2,
                            (fromMesh.position.y + toMesh.position.y) / 2 + (Math.random() * 0.2 - 0.1),
                            (fromMesh.position.z + toMesh.position.z) / 2 + (Math.random() * 0.2 - 0.1)
                        ),
                        new THREE.Vector3(toMesh.position.x, toMesh.position.y, toMesh.position.z)
                    );
                    
                    const points = curve.getPoints(20);
                    const lineGeometry = new THREE.BufferGeometry().setFromPoints(points);
                    const lineMaterial = new THREE.LineBasicMaterial({ 
                        color: 0x999999,
                        opacity: 0.7,
                        transparent: true
                    });
                    const line = new THREE.Line(lineGeometry, lineMaterial);
                    
                    scene.add(line);
                    layerObjects.push(line);
                }
                
                // Helper function to find the mesh for a specific layer
                function findMeshForLayer(targetLayer) {
                    for (const obj of layerObjects) {
                        if (obj.userData && obj.userData.layer === targetLayer) {
                            return obj;
                        }
                    }
                    return null;
                }
            }
        </script>


    </body>
</html>